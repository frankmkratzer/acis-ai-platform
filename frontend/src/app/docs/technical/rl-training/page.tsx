'use client'
export default function RLTraining() {
  return (<div className="prose prose-blue max-w-none"><h1 className="text-4xl font-bold mb-4">RL Training</h1><p className="text-xl text-gray-600 mb-8">PPO reinforcement learning implementation and training process.</p><section className="mb-8"><h2 className="text-2xl font-bold mb-4">PPO Agent</h2><p className="text-sm">Proximal Policy Optimization for portfolio weight optimization</p><div className="bg-gray-50 p-3 rounded text-xs mt-3"><p><strong>Environment:</strong> Custom Gymnasium env with historical market data</p><p><strong>Action Space:</strong> Portfolio weights for top 50 stocks</p><p><strong>Reward:</strong> Sharpe ratio with transaction cost penalty</p><p><strong>Training Time:</strong> 1M timesteps, ~2-4 hours on GPU</p></div></section><section className="mb-8"><h2 className="text-2xl font-bold mb-4">Training Command</h2><div className="bg-gray-900 text-gray-100 p-3 rounded font-mono text-xs not-prose">python rl_trading/incremental_train_ppo.py \<br/>&nbsp;&nbsp;--strategy growth \<br/>&nbsp;&nbsp;--market-cap mid \<br/>&nbsp;&nbsp;--timesteps 1000000 \<br/>&nbsp;&nbsp;--device cuda</div></section></div>)
}
